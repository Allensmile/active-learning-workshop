---
title: "Plot Batch Results"
author: "Bob"
date: "1/26/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, cache=FALSE, fig.height=10)
```


```{r load_libraries, message=FALSE}
library(dplyr)
library(ggplot2)

DATA_DIR <- "lambda_scans4"
 # In the facet grid, the metacolumns represent different random number seeds, and the metarows show different candidate groups. Each candidate group represents a randomly selected subset of samples on which active learning was run, and is labelled `A`, `B`, or `C`. Models trained on each of these groups were tested on the next group (e.g., a model trained on group `A` was tested on group `B`).
```

These plots show the results generated by the script `batch_active_learning.R` in the `r DATA_DIR` directory.

```{r load_data}

run_to_dataframe <- function(run){
  run %>% 
    lapply(function(iter) iter[c('iteration', 'tss', 'auc', 'lambda', 'selection_mode')]) %>%  # , 'alpha'
    bind_rows
}

parse_filename <- function(filename){
  # filename <- "learning_curve_run100002_100x99_rep1_seed1_AvsB_mu0.50_sigma0.10_lambda0.20_alpha0.00.Rds"
  re_pat <- '^.*run(\\d+)_(\\d+)x(\\d+)_rep(\\d+)_seed(\\d+)_([A-Z])vs([A-Z])_mu([0-9.]+)_sigma([0-9.]+)_lambda([0-9.]+)_alpha([0-9.]+).Rds'
  sub_pat <- "params_id=\\1;step_size=\\2;iterations=\\3;rep=\\4;seed=\\5;candidate_group=\\6;test_group=\\7;mu=\\8;sigma=\\9;"
  # re_pat2 <- "_lambda([0-9.]+)_alpha([0-9.]+).Rds"
  # sub_pat2 <- "lambda=\\1;alpha=\\2"
  filename %>% 
    gsub(re_pat, sub_pat, .) %>% 
    # gsub(re_pat2, sub_pat2, .) %>% 
    strsplit(';') %>% '[['(1) %>%
    strsplit('=') %>% 
    do.call(rbind, .) %>% 
    (function(M) setNames(M[,2], nm=M[,1])) %>% 
    as.list %>%
    as_tibble
}

load_run <- function(filename){

  file_info <- filename %>% parse_filename

  file_dataframe <- filename %>% 
    file.path(DATA_DIR, .) %>% 
    readRDS %>% 
    run_to_dataframe

  file_dataframe %>% 
    mutate(
      params_id=file_info$params_id,
      seed=file_info$seed,
      rep=file_info$rep,
      candidate_group=file_info$candidate_group,
      test_group=file_info$test_group,
      mu=file_info$mu,
      sigma=file_info$sigma
    )
}

all_results <- DATA_DIR %>% 
  list.files(pattern='*.Rds') %>% # full.names=TRUE, 
  lapply(load_run) %>% 
  bind_rows %>% 
  mutate(selection_mode=factor(selection_mode), candidate_group=factor(candidate_group), test_group=factor(test_group),
         seed=as.integer(seed), mu=as.numeric(mu), sigma=as.numeric(sigma), lambda=as.numeric(lambda))
```

## Plots showing individual replicates

```{r plot_results}
all_results  %>% 
  # filter(seed==1, candidate_group=='B') %>% filter(lambda > 0.0001) %>% 
  ggplot(aes(x=tss, y=auc, col=log10(lambda), linetype=selection_mode, group=interaction(lambda, rep, params_id))) + geom_line() + 
  # ylim(c(0.9, max(all_results$auc))) + 
  scale_colour_gradientn(colours=rainbow(16, end=2/3, v=0.7)) +
  facet_grid(candidate_group ~ .) + 
  ggtitle("Learning curves by candidate group")

all_results  %>% 
  # filter(seed==1, candidate_group=='B') %>% 
  filter(lambda > 0.0001) %>% 
  ggplot(aes(x=log10(tss), y=auc, col=log10(lambda), linetype=selection_mode, group=interaction(lambda, rep, params_id))) + geom_line() + 
  scale_colour_gradientn(colours=rainbow(16, end=2/3, v=0.7)) +
  facet_grid(candidate_group ~ .) + 
  ggtitle("Learning curves by candidate group (log tss)")

```

## Plot mean AUC for each set of replicates

```{r mean_across_runs}

avg_across_runs <- all_results %>% 
  group_by(candidate_group, iteration, tss, lambda, selection_mode) %>%
  summarize(mean_auc=mean(auc))

avg_across_runs %>% 
  ggplot(aes(x=log10(tss), y=mean_auc, col=log10(lambda), group=interaction(lambda, selection_mode), linetype=selection_mode)) + geom_line() + 
  scale_colour_gradientn(colours=rainbow(16, end=2/3, v=0.7)) +
  facet_grid(candidate_group ~ .) + 
  ggtitle("Optimum lambda changes with training set size")


avg_across_runs  %>% 
  filter(selection_mode=="passive") %>%
  ggplot(aes(x=log10(tss), y=mean_auc, col=log10(lambda), group=lambda)) + geom_line() + 
  scale_colour_gradientn(colours=rainbow(16, end=2/3, v=0.7)) +
  facet_grid(candidate_group ~ .) + 
  ggtitle("Optimum lambda for passive learning changes with training set size")

avg_across_runs  %>% 
  filter(selection_mode=="active") %>%
  ggplot(aes(x=log10(tss), y=mean_auc, col=log10(lambda), group=lambda)) + geom_line() + 
  scale_colour_gradientn(colours=rainbow(16, end=2/3, v=0.7)) +
  facet_grid(candidate_group ~ .) + 
  ggtitle("Optimum lambda for active learning changes with training set size")


```

# Individual plots

```{r individual_lambda_plots, fig.height=4}
avg_across_runs %>% 
  filter(candidate_group=='A', lambda %in% c(1e-4, 1e-2, 1e-1, 1)) %>%
  ggplot(aes(x=log10(tss), y=mean_auc, linetype=selection_mode)) + geom_line() + 
  scale_colour_gradientn(colours=rainbow(16, end=2/3, v=0.7)) +
  facet_grid(candidate_group ~ lambda) + 
  ggtitle("Mean AUC plots for different values of lambda")

```