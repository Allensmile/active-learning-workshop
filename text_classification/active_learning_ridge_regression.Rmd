---
title: "Active Learning for Text Classification"
output: html_document
params:
  examples_per_iteration: 100 #10           # number of cases to label and add to training set per iteration
  num_iterations: 20 # 990                  # number of iterations of active learning
  num_replicates: 3                    # number of replicates of each learning curves
  mu: 0.5                              # mean of probability for uncertainty sampling weighting
  sigma: 0.1                           # standard deviation for uncertainty sampling weighting
  candidate_group: 'A'                 # group ('A', 'B', or 'C;) used for candidate pool
  test_group: 'B'                      # group (different from candidate group) used for test set
  seed: 1                              # seed for random number generator
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo=TRUE, cache=FALSE, message=FALSE, warning=FALSE, fig.height=7.5)

```

# Classifying Wiki Detox Comments

Here we use a simple active learning approach for building a text classifier.

```{r load_libraries_and_data}

library(dplyr)
library(tidyr)
library(ggplot2)
library(pROC)
library(glmnet)
library(feather)
library(RColorBrewer)

ALL_DATA <- read_feather("wiki_attacks_use_encoded_30k.feather")

```

```{r print_parameters}
params
```

## Global objects

```{r initialize}
set.seed(params$seed)

subset_name <- sample(rep(LETTERS[1:3], times=nrow(ALL_DATA)/3))
table(subset_name)

CANDIDATE_SET <- ALL_DATA[subset_name==params$candidate_group,]
TEST_SET <- ALL_DATA[subset_name==params$test_group,]

INPUTS <- names(CANDIDATE_SET)[1:512]
OUTCOME <- "flagged"

# We need at least 100 labeled cases to train the initial model so we can measure AUC
# with k-fold cross-validation on 10 folds.
INITIAL_TRAINING_CASES <- with(CANDIDATE_SET, {
  sample(rev_id, 100)
})

# Be sure that there are some examples from each class
CANDIDATE_SET[CANDIDATE_SET$rev_id %in% INITIAL_TRAINING_CASES, 'flagged'] %>% table

NULL_MODEL <- "This is not really a model, just a placeholder for method dispatch."
class(NULL_MODEL) <- "null_model"
predict.null_model <- function(object, newx, type) matrix(runif(nrow(newx)), ncol=1)

TRAINING_CASES <- INITIAL_TRAINING_CASES


```

## Functions for active and passive learning curves
```{r learning_curve_functions}
select_new_cases <- function(current_model, n, sigma=0.1, mu=0.5){
  available_cases <- CANDIDATE_SET[!(CANDIDATE_SET$rev_id %in% TRAINING_CASES),]
  X_available <- as.matrix(available_cases[INPUTS])
  category_prob <- predict(current_model, newx=X_available, type="response")[,1]
  selection_weight <- dnorm(category_prob, mean=mu, sd=sigma)
  sample(available_cases$rev_id, size=n, prob=selection_weight)
}

# https://stackoverflow.com/questions/40145209/cv-glmnet-fails-for-ridge-not-lasso-for-simulated-data-with-coder-error
fit_and_select <- function(iteration_num, cases_per_iteration, selection_mode="active"){
  training_set <- CANDIDATE_SET[CANDIDATE_SET$rev_id %in% TRAINING_CASES,]
  
  alpha <- 0.0
  lambda <- 0.5
  X_train <- training_set[INPUTS] %>% as.matrix
  y_train <- training_set[[OUTCOME]]
  model <- glmnet(X_train, y_train, alpha=alpha, 
                      lambda=lambda, 
                      family="binomial")

  selection_model <- if (selection_mode == "active") model else NULL_MODEL
  new_cases <- select_new_cases(selection_model, n=cases_per_iteration)
  TRAINING_CASES <<- c(TRAINING_CASES, new_cases)
  
  list(model=model, 
       iteration=iteration_num, 
       lambda = model$lambda,
       kfold_auc = model$cvm,
       tss = model$nobs,
       selection_mode=selection_mode, 
       new_cases=paste(new_cases, collapse=','))
}

do_training_run <- function(run_number, num_iterations, ...){
  TRAINING_CASES <<- INITIAL_TRAINING_CASES
  run_results <- lapply(1:num_iterations, fit_and_select, ...)
}

```


## Run active and passive learning curves
```{r run_learning_curves}
active_learning_runs <- lapply(1:params$num_replicate, do_training_run, 
                               num_iterations=params$num_iterations, 
                               cases_per_iteration=params$examples_per_iteration)

passive_learning_runs <- lapply(1:params$num_replicate, do_training_run, 
                                num_iterations=params$num_iterations, 
                                cases_per_iteration=params$examples_per_iteration, 
                                selection_mode="passive")
```

```{r save_results}
learning_runs <- c(active_learning_runs, passive_learning_runs)

tag <- with(params, sprintf("%dx%dx%d_seed%d_%svs%s", 
                            examples_per_iteration, 
                            num_iterations,
                            num_replicates,
                            seed,
                            candidate_group,
                            test_group))

learning_results_file <- sprintf("ridge_learning_runs_%s.Rds", tag)

saveRDS(learning_runs, learning_results_file)

# learning_runs <- readRDS(learning_results_file)

```

## Format and plot results

```{r format_results}
run_results_as_df <- function(run_results, run_number){
  keep_columns <- c("tss", "lambda", "selection_mode")
  rrdf <- run_results %>% lapply(function(rr) rr[keep_columns]) %>% bind_rows
  rrdf$run_number <- run_number
  rrdf
}

results_df <- learning_runs %>% 
  seq_along %>% 
  lapply(function(i) run_results_as_df(learning_runs[[i]], i)) %>% 
  bind_rows

```

## Evaluate on held-out test set

```{r test_set_evaluation}
X_test <- TEST_SET[INPUTS] %>% as.matrix
y_test <- TEST_SET[[OUTCOME]]

evaluate_iteration_auc <- function(iteration, X_test, y_test){
  model <- iteration$model
  pred <- predict(model, X_test, type="response")[,1]
  pROC::auc(factor(y_test), pred, direction='<') %>% as.numeric
}

evaluate_run <- function(run_results, X_test, y_test){
  lapply(run_results, evaluate_iteration_auc, X_test, y_test) %>% unlist
}

results_df$test_set_auc <- lapply(learning_runs, evaluate_run, X_test, y_test) %>% unlist

```

```{r plot_results}
results_df %>% ggplot(aes(x=tss, y=test_set_auc, col=selection_mode, group=run_number)) + geom_line()
```
