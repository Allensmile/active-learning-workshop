{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text classification on Spark with MMLSpark\n",
    "\n",
    "This notebook shows how to make a text classfication web service using MML Spark serving and deploy it to a Sparl cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files here\n"
     ]
    }
   ],
   "source": [
    "# get the text data from the github repo and unzip it\n",
    "from fit_and_store_pipeline import unzip_file_here\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "if not os.path.isfile('./text_data/attack_data.csv'):\n",
    "    if not os.path.isfile('./text_data.zip'): \n",
    "        urllib.request.urlretrieve('https://activelearning.blob.core.windows.net/activelearningdemo/text_data.zip', 'text_data.zip')\n",
    "    unzip_file_here('text_data.zip')\n",
    "\n",
    "if not os.path.isfile('miniglove_6B_50d_w2v.txt'):\n",
    "    unzip_file_here('miniglove_6B_50d_w2v.zip')\n",
    "    \n",
    "print('Data files here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a train-test data pair\n",
    "\n",
    "from fit_and_store_pipeline import create_train_test_split\n",
    "\n",
    "# requires training_set_01.csv and test_set_01.csv to be present\n",
    "training_data, test_data = create_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data in the spark format\n",
    "\n",
    "train_sdf = spark.createDataFrame(training_data)\n",
    "train_sdf = train_sdf\\\n",
    "            .withColumn(\"label\", train_sdf[\"is_attack\"].cast('integer'))\\\n",
    "            .select([\"comment\", \"label\"])\n",
    "                                                             \n",
    "test_sdf = spark.createDataFrame(test_data)\n",
    "test_sdf = test_sdf\\\n",
    "            .withColumn(\"label\", test_sdf[\"is_attack\"].cast('integer'))\\\n",
    "            .select([\"comment\", \"label\"])\n",
    "\n",
    "# What have we?\n",
    "# train_sdf.limit(10).toPandas()\n",
    "# train_sdf.groupBy(\"label\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an ML-Lib pipeline involving preprocessor and vectorizer\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# comment is the text field\n",
    "tokenizer = Tokenizer(inputCol=\"comment\", outputCol=\"words\")\n",
    "partitions = train_sdf.rdd.getNumPartitions()\n",
    "word2vec = Word2Vec(maxIter=4, seed=44, inputCol=\"words\", outputCol=\"features\",\n",
    "                    numPartitions=partitions)\n",
    "rfc = RandomForestClassifier(labelCol=\"label\")\n",
    "textClassifier = Pipeline(stages = [tokenizer, word2vec, rfc]).fit(train_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.197263322771, 0.021295234561, 0.0276349233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.240008686802, 0.117446979774, -0.058907808...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.274001607099, 0.127858318913, -0.087485656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.166309199855, 0.141414361075, -0.047271387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.270946531485, 0.090287042728, -0.037509560...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0      0  [-0.197263322771, 0.021295234561, 0.0276349233...\n",
       "1      0  [-0.240008686802, 0.117446979774, -0.058907808...\n",
       "2      0  [-0.274001607099, 0.127858318913, -0.087485656...\n",
       "3      0  [-0.166309199855, 0.141414361075, -0.047271387...\n",
       "4      0  [-0.270946531485, 0.090287042728, -0.037509560..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you are going to try a couple different models, pre-featurize first\n",
    "textFeaturizer = Pipeline(stages = [tokenizer, word2vec]).fit(train_sdf)\n",
    "ptrain = textFeaturizer.transform(train_sdf).select([\"label\", \"features\"])\n",
    "ptest = textFeaturizer.transform(test_sdf).select([\"label\", \"features\"])\n",
    "ptrain.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>words</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are scum.</td>\n",
       "      <td>[you, are, scum.]</td>\n",
       "      <td>[-0.421156624953, 0.194889614979, -0.121429090...</td>\n",
       "      <td>[9.5761742881, 10.4238257119]</td>\n",
       "      <td>[0.478808714405, 0.521191285595]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I like your shoes.</td>\n",
       "      <td>[i, like, your, shoes.]</td>\n",
       "      <td>[-0.217787927017, 0.201306108385, 0.0849744305...</td>\n",
       "      <td>[11.6430517863, 8.35694821373]</td>\n",
       "      <td>[0.582152589314, 0.417847410686]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are pxzx.</td>\n",
       "      <td>[you, are, pxzx.]</td>\n",
       "      <td>[-0.421156624953, 0.194889614979, -0.121429090...</td>\n",
       "      <td>[9.5761742881, 10.4238257119]</td>\n",
       "      <td>[0.478808714405, 0.521191285595]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your mother was a hamster and your father smel...</td>\n",
       "      <td>[your, mother, was, a, hamster, and, your, fat...</td>\n",
       "      <td>[-0.299377459017, 0.195304373449, -0.186904550...</td>\n",
       "      <td>[9.65799917433, 10.3420008257]</td>\n",
       "      <td>[0.482899958716, 0.517100041284]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One bag of hagfish slime, please</td>\n",
       "      <td>[one, bag, of, hagfish, slime,, please]</td>\n",
       "      <td>[-0.28979960084, 0.345299651225, -0.2011535658...</td>\n",
       "      <td>[11.4189348584, 8.5810651416]</td>\n",
       "      <td>[0.57094674292, 0.42905325708]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0                                      You are scum.   \n",
       "1                                 I like your shoes.   \n",
       "2                                      You are pxzx.   \n",
       "3  Your mother was a hamster and your father smel...   \n",
       "4                   One bag of hagfish slime, please   \n",
       "\n",
       "                                               words  \\\n",
       "0                                  [you, are, scum.]   \n",
       "1                            [i, like, your, shoes.]   \n",
       "2                                  [you, are, pxzx.]   \n",
       "3  [your, mother, was, a, hamster, and, your, fat...   \n",
       "4            [one, bag, of, hagfish, slime,, please]   \n",
       "\n",
       "                                            features  \\\n",
       "0  [-0.421156624953, 0.194889614979, -0.121429090...   \n",
       "1  [-0.217787927017, 0.201306108385, 0.0849744305...   \n",
       "2  [-0.421156624953, 0.194889614979, -0.121429090...   \n",
       "3  [-0.299377459017, 0.195304373449, -0.186904550...   \n",
       "4  [-0.28979960084, 0.345299651225, -0.2011535658...   \n",
       "\n",
       "                    rawPrediction                       probability  \\\n",
       "0   [9.5761742881, 10.4238257119]  [0.478808714405, 0.521191285595]   \n",
       "1  [11.6430517863, 8.35694821373]  [0.582152589314, 0.417847410686]   \n",
       "2   [9.5761742881, 10.4238257119]  [0.478808714405, 0.521191285595]   \n",
       "3  [9.65799917433, 10.3420008257]  [0.482899958716, 0.517100041284]   \n",
       "4   [11.4189348584, 8.5810651416]    [0.57094674292, 0.42905325708]   \n",
       "\n",
       "   prediction  \n",
       "0         1.0  \n",
       "1         0.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction on some new data\n",
    "import pandas as pd\n",
    "\n",
    "test_attacks = ['You are scum.', 'I like your shoes.', 'You are pxzx.', \n",
    "             'Your mother was a hamster and your father smelt of elderberries',\n",
    "             'One bag of hagfish slime, please']\n",
    "\n",
    "ta_sdf = spark.createDataFrame(pd.DataFrame({\"comment\" : test_attacks}))\n",
    "\n",
    "prediction = textClassifier.transform(ta_sdf)\n",
    "prediction.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>818</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count    \n",
       "prediction   0.0 1.0\n",
       "label               \n",
       "0            818  31\n",
       "1            130  21"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction on the larger test set\n",
    "\n",
    "scored_test = textClassifier.transform(test_sdf)\n",
    "scored_test.groupBy([\"label\", \"prediction\"]).count()\\\n",
    "            .toPandas().pivot(index=\"label\", columns=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o4523.transform.\n: java.lang.Exception: Please score the model prior to evaluating\n\tat com.microsoft.ml.spark.metrics.MetricUtils$.getSchemaInfo(MetricUtils.scala:27)\n\tat com.microsoft.ml.spark.ComputeModelStatistics.transform(ComputeModelStatistics.scala:71)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-5e184f1cb0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# why does this not work? Is it because the model is a pipeline?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmlspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComputeModelStatistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeModelStatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscored_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/spark/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/spark/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o4523.transform.\n: java.lang.Exception: Please score the model prior to evaluating\n\tat com.microsoft.ml.spark.metrics.MetricUtils$.getSchemaInfo(MetricUtils.scala:27)\n\tat com.microsoft.ml.spark.ComputeModelStatistics.transform(ComputeModelStatistics.scala:71)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "# why does this not work? Is it because the model is a pipeline?\n",
    "from mmlspark import ComputeModelStatistics\n",
    "metrics = ComputeModelStatistics().transform(scored_test)\n",
    "metrics.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model as a Spark Streaming job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now deploy the trained classifier as a streaming job\n",
    "# define the interface to be like the model's input\n",
    "\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import *\n",
    "import uuid\n",
    "\n",
    "serving_inputs = spark.readStream.server() \\\n",
    "    .address(\"localhost\", 9977, \"text_api\") \\\n",
    "    .load()\\\n",
    "    .withColumn(\"variables\", from_json(col(\"value\"), test_sdf.schema))\\\n",
    "    .select(\"id\",\"variables.*\")\n",
    "\n",
    "# says to extract \"variables\" from the \"value\" field of json-encoded webservice input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_outputs = textClassifier.transform(serving_inputs) \\\n",
    "  .withColumn(\"prediction\", col(\"prediction\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = serving_outputs.writeStream \\\n",
    "    .server() \\\n",
    "    .option(\"name\", \"text_api\") \\\n",
    "    .queryName(\"mml_text_query\") \\\n",
    "    .option(\"replyCol\", \"prediction\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoints-{}\".format(uuid.uuid1())) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we want to change something above, we'll need\n",
    "# to stop the active server\n",
    "\n",
    "server.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, comment: string, label: int]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs and outputs - schema\n",
    "serving_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, comment: string, label: int, words: array<string>, features: vector, rawPrediction: vector, probability: vector, prediction: string]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to : 'You are scum.' is 1.0\n",
      "Response to : 'I like your shoes.' is 0.0\n",
      "Response to : 'You are pxzx.' is 1.0\n",
      "Response to : 'Your mother was a hamster and your father smelt of elderberries' is 1.0\n",
      "Response to : 'One bag of hagfish slime, please' is 0.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# calling the service\n",
    "data = pd.DataFrame({ \"comment\" : test_attacks })\n",
    "\n",
    "for instance in range(len(test_attacks)):    \n",
    "    row_as_dict = data.to_dict('records')[instance]        \n",
    "    r = requests.post(data=json.dumps(row_as_dict), url=\"http://localhost:9977/text_api\")\n",
    "    time.sleep(0.5)\n",
    "    print(\"Response to : '{}' is {}\".format(test_attacks[instance], r.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
